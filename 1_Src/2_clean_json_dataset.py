import os
import json
import re
import nltk
from nltk.tokenize import sent_tokenize

# ä¸‹è½½nltkèµ„æºï¼ˆå¦‚æœå°šæœªä¸‹è½½ï¼‰
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

# è¾…åŠ©å‡½æ•°ï¼šå°†æ–‡æœ¬æ‹†åˆ†æˆå¥å­
def split_sentences(text):
    """
    å°†é•¿æ–‡æœ¬æ‹†åˆ†æˆå¥å­åˆ—è¡¨
    """
    if not text or not isinstance(text, str):
        return []
    
    # é¢„å¤„ç†æ–‡æœ¬ï¼Œå¤„ç†ç‰¹æ®Šæƒ…å†µ
    # 1. å¤„ç†ç¼©å†™è¯ï¼Œé¿å…é”™è¯¯æ‹†åˆ†
    text = re.sub(r'(Mr\.|Mrs\.|Dr\.|Prof\.|etc\.)', r'\1<POINT>', text)
    # 2. å¤„ç†æ•°å­—ç¼–å·åçš„ç‚¹ï¼Œé¿å…é”™è¯¯æ‹†åˆ†
    text = re.sub(r'(\d+)\.(\s)', r'\1<POINT>\2', text)
    # 3. å¤„ç†æ–‡ä»¶æ‰©å±•åï¼Œé¿å…é”™è¯¯æ‹†åˆ†
    text = re.sub(r'(\.[a-zA-Z]{2,4})\s', r'<POINT>\1 ', text)
    
    # 4. å¤„ç†å¤§å†™çš„ OR ä½œä¸ºæ–­å¥æ ‡å¿—ï¼ˆç¡®ä¿å°å†™çš„ or ä¸å—å½±å“ï¼‰
    text = re.sub(r'\s+OR\s+', '. ', text)
    
    # ä½¿ç”¨nltkæ‹†åˆ†å¥å­
    sentences = sent_tokenize(text)
    
    # è¿˜åŸç‰¹æ®Šæ ‡è®°
    sentences = [s.replace('<POINT>', '.') for s in sentences]
    
    # æ¸…ç†æ¯ä¸ªå¥å­
    sentences = [s.strip() for s in sentences if s.strip()]
    
    return sentences

# eANCI_en.json æ¸…æ´—å‡½æ•°
def clean_eanci(data):
    cleaned_data = []
    
    for item in data:
        cleaned_item = item.copy()
        
        # ç§»é™¤ Original å­—æ®µ
        if "Original" in cleaned_item:
            cleaned_item.pop("Original")
        
        # ç»Ÿä¸€å­—æ®µåç§°
        if "Use Case Name" in cleaned_item:
            cleaned_item["Name"] = cleaned_item.pop("Use Case Name")
        
        if "Participating Actors" in cleaned_item:
            actors = cleaned_item.pop("Participating Actors")
            # å°†å‚ä¸è€…æ‹†åˆ†ä¸ºåˆ—è¡¨
            if isinstance(actors, str):
                actors_list = [actor.strip() for actor in re.split(r'[,;]', actors) if actor.strip()]
                cleaned_item["Actors"] = actors_list
        
        if "Flow of Events" in cleaned_item:
            flow = cleaned_item.pop("Flow of Events")
            # å¤„ç†äº‹ä»¶æµï¼Œç¡®ä¿æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
            if isinstance(flow, list):
                # åˆå¹¶åˆ—è¡¨é¡¹ï¼Œç„¶åé‡æ–°æ‹†åˆ†æˆå¥å­
                combined_text = " ".join(flow)
                cleaned_item["Basic flow"] = split_sentences(combined_text)
            else:
                cleaned_item["Basic flow"] = split_sentences(flow)
        
        if "Entry Condition" in cleaned_item:
            entry_cond = cleaned_item.pop("Entry Condition")
            # å¤„ç†å…¥å£æ¡ä»¶ï¼Œç¡®ä¿æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
            if isinstance(entry_cond, list):
                # åˆå¹¶åˆ—è¡¨é¡¹ï¼Œç„¶åé‡æ–°æ‹†åˆ†æˆå¥å­
                combined_text = " ".join(entry_cond)
                cleaned_item["Precondition"] = split_sentences(combined_text)
            else:
                cleaned_item["Precondition"] = split_sentences(entry_cond)
        
        if "Exit Conditions" in cleaned_item:
            exit_cond = cleaned_item.pop("Exit Conditions")
            # å¤„ç†å‡ºå£æ¡ä»¶ï¼Œç¡®ä¿æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
            if isinstance(exit_cond, list):
                # åˆå¹¶åˆ—è¡¨é¡¹ï¼Œç„¶åé‡æ–°æ‹†åˆ†æˆå¥å­
                combined_text = " ".join(exit_cond)
                cleaned_item["Postcondition"] = split_sentences(combined_text)
            else:
                cleaned_item["Postcondition"] = split_sentences(exit_cond)
        
        if "Quality Requirements" in cleaned_item:
            quality_req = cleaned_item.pop("Quality Requirements")
            # å¤„ç†è´¨é‡è¦æ±‚ï¼Œç¡®ä¿æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
            if isinstance(quality_req, list):
                # åˆå¹¶åˆ—è¡¨é¡¹ï¼Œç„¶åé‡æ–°æ‹†åˆ†æˆå¥å­
                combined_text = " ".join(quality_req)
                cleaned_item["Quality Requirements"] = split_sentences(combined_text)
            else:
                cleaned_item["Quality Requirements"] = split_sentences(quality_req)
        
        cleaned_data.append(cleaned_item)
    
    return cleaned_data

# SMOS_en.json æ¸…æ´—å‡½æ•°
def clean_smos(data):
    cleaned_data = []
    
    for item in data:
        cleaned_item = item.copy()
        
        # ç§»é™¤ Original å­—æ®µ
        if "Original" in cleaned_item:
            cleaned_item.pop("Original")
        
        # å¤„ç†Actorså­—æ®µï¼Œå°†å…¶è½¬æ¢ä¸ºåˆ—è¡¨
        if "Actors" in cleaned_item and isinstance(cleaned_item["Actors"], str):
            actors = cleaned_item["Actors"]
            actors_list = [actor.strip() for actor in re.split(r'[,;]', actors) if actor.strip()]
            cleaned_item["Actors"] = actors_list
        
        # å¤„ç†Preconditionå­—æ®µï¼Œç¡®ä¿æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
        if "Precondition" in cleaned_item:
            precond = cleaned_item["Precondition"]
            if isinstance(precond, list):
                # åˆå¹¶åˆ—è¡¨é¡¹ï¼Œç„¶åé‡æ–°æ‹†åˆ†æˆå¥å­
                combined_text = " ".join(precond)
                cleaned_item["Precondition"] = split_sentences(combined_text)
        
        # å¤„ç†Sequence of eventså­—æ®µï¼Œç¡®ä¿æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
        if "Sequence of events" in cleaned_item:
            seq_events = cleaned_item.pop("Sequence of events")
            if isinstance(seq_events, list):
                # æ¸…ç†æ¯ä¸ªäº‹ä»¶ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_events = []
                for event in seq_events:
                    # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                    event = re.sub(r'^\d+\.?\s*', '', event)
                    # æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(event)
                    cleaned_events.extend(sentences)
                cleaned_item["Basic flow"] = cleaned_events
            else:
                cleaned_item["Basic flow"] = split_sentences(seq_events)
        
        # å¤„ç†Postconditionå­—æ®µï¼Œç¡®ä¿æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
        if "Postcondition" in cleaned_item:
            postcond = cleaned_item["Postcondition"]
            if isinstance(postcond, list):
                # åˆå¹¶åˆ—è¡¨é¡¹ï¼Œç„¶åé‡æ–°æ‹†åˆ†æˆå¥å­
                combined_text = " ".join(postcond)
                cleaned_item["Postcondition"] = split_sentences(combined_text)
        
        cleaned_data.append(cleaned_item)
    
    return cleaned_data

# eTour.json æ¸…æ´—å‡½æ•°
def clean_etour(data):
    cleaned_data = []
    
    for item in data:
        cleaned_item = item.copy()
        
        # å¤„ç†Actorså­—æ®µï¼Œå°†å…¶è½¬æ¢ä¸ºåˆ—è¡¨
        if "Actors" in cleaned_item and isinstance(cleaned_item["Actors"], str):
            actors = cleaned_item["Actors"]
            actors_list = [actor.strip() for actor in re.split(r'[,;]', actors) if actor.strip()]
            cleaned_item["Actors"] = actors_list
        
        # å¤„ç†Preconditionå­—æ®µï¼Œç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼
        if "Precondition" in cleaned_item and isinstance(cleaned_item["Precondition"], str):
            precond = cleaned_item["Precondition"]
            cleaned_item["Precondition"] = split_sentences(precond)
        
        # å¤„ç†Basic flowå­—æ®µï¼Œç¡®ä¿æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
        if "Basic flow" in cleaned_item:
            basic_flow = cleaned_item["Basic flow"]
            if isinstance(basic_flow, list):
                # æ¸…ç†æ¯ä¸ªæ­¥éª¤ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_steps = []
                for step in basic_flow:
                    # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                    step = re.sub(r'^\d+\.?\s*', '', step)
                    # æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(step)
                    cleaned_steps.extend(sentences)
                cleaned_item["Basic flow"] = cleaned_steps
        
        # å¤„ç†Postconditionå­—æ®µï¼Œç¡®ä¿æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
        if "Postcondition" in cleaned_item:
            postcond = cleaned_item["Postcondition"]
            if isinstance(postcond, list):
                # æ¸…ç†æ¯ä¸ªæ¡ä»¶ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_postcond = []
                for cond in postcond:
                    # æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(cond)
                    cleaned_postcond.extend(sentences)
                cleaned_item["Postcondition"] = cleaned_postcond
        
        # å¤„ç†Quality requirementså­—æ®µï¼Œç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼
        if "Quality requirements" in cleaned_item and isinstance(cleaned_item["Quality requirements"], str):
            quality_req = cleaned_item["Quality requirements"]
            cleaned_item["Quality requirements"] = split_sentences(quality_req)
        
        cleaned_data.append(cleaned_item)
    
    return cleaned_data

# easyClinic.json æ¸…æ´—å‡½æ•°
def clean_easyclinic(data):
    cleaned_data = []
    
    for item in data:
        cleaned_item = item.copy()
        
        # å¤„ç†Alt. Flowå­—æ®µï¼Œç¡®ä¿æ ¼å¼ä¸€è‡´
        if "Alt. Flow" in cleaned_item:
            alt_flow = cleaned_item["Alt. Flow"]
            if isinstance(alt_flow, list):
                # æ¸…ç†æ¯ä¸ªå¤‡é€‰æµç¨‹ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_alt_flow = []
                for flow in alt_flow:
                    # ç¡®ä¿ flow æ˜¯å­—ç¬¦ä¸²ç±»å‹
                    if isinstance(flow, str):
                        # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                        flow = re.sub(r'^\d+\.?\s*', '', flow)
                        # æ‹†åˆ†æˆå¥å­
                        sentences = split_sentences(flow)
                        cleaned_alt_flow.extend(sentences)
                    else:
                        print(f"è­¦å‘Šï¼šåœ¨ Alt. Flow ä¸­å‘ç°éå­—ç¬¦ä¸²å…ƒç´ ï¼š{flow}")
                cleaned_item["Alt. Flow"] = cleaned_alt_flow
        
        # å¤„ç†Basic flowå­—æ®µï¼Œç¡®ä¿æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
        if "Basic flow" in cleaned_item:
            basic_flow = cleaned_item["Basic flow"]
            if isinstance(basic_flow, list):
                # æ¸…ç†æ¯ä¸ªæ­¥éª¤ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_steps = []
                for step in basic_flow:
                    # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                    step = re.sub(r'^\d+\.?\s*', '', step)
                    # æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(step)
                    cleaned_steps.extend(sentences)
                cleaned_item["Basic flow"] = cleaned_steps
        
        cleaned_data.append(cleaned_item)
    
    return cleaned_data

# g02-uc-cm-req.json æ¸…æ´—å‡½æ•°
def clean_g02(data):
    cleaned_data = []
    
    for item in data:
        cleaned_item = item.copy()
        
        # å¤„ç†Actorså­—æ®µï¼Œç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼
        if "Actors" in cleaned_item and not isinstance(cleaned_item["Actors"], list):
            actors = cleaned_item["Actors"]
            if isinstance(actors, str):
                actors_list = [actor.strip() for actor in re.split(r'[,;]', actors) if actor.strip()]
                cleaned_item["Actors"] = actors_list
        
        # å¤„ç†Basic flowå­—æ®µï¼Œç¡®ä¿æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
        if "Basic flow" in cleaned_item:
            basic_flow = cleaned_item["Basic flow"]
            if isinstance(basic_flow, list):
                # æ¸…ç†æ¯ä¸ªæ­¥éª¤ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_steps = []
                for step in basic_flow:
                    # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                    step = re.sub(r'^\d+\.?\s*', '', step)
                    # æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(step)
                    cleaned_steps.extend(sentences)
                cleaned_item["Basic flow"] = cleaned_steps
            elif isinstance(basic_flow, str):
                cleaned_item["Basic flow"] = split_sentences(basic_flow)
        
        # å¤„ç†Alt. Flowå­—æ®µï¼Œç¡®ä¿æ ¼å¼ä¸€è‡´
        if "Alt. Flow" in cleaned_item:
            alt_flow = cleaned_item["Alt. Flow"]
            if isinstance(alt_flow, list):
                # æ¸…ç†æ¯ä¸ªå¤‡é€‰æµç¨‹ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_alt_flow = []
                for flow in alt_flow:
                    # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                    flow = re.sub(r'^\d+\.?\s*', '', flow)
                    # æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(flow)
                    cleaned_alt_flow.extend(sentences)
                cleaned_item["Alt. Flow"] = cleaned_alt_flow
            elif isinstance(alt_flow, str):
                cleaned_item["Alt. Flow"] = split_sentences(alt_flow)
        
        # å¤„ç†Postconditionå­—æ®µï¼Œç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼
        if "Postcondition" in cleaned_item and isinstance(cleaned_item["Postcondition"], str):
            postcond = cleaned_item["Postcondition"]
            cleaned_item["Postcondition"] = split_sentences(postcond)
        
        cleaned_data.append(cleaned_item)
    
    return cleaned_data

# g04-uc-req.json æ¸…æ´—å‡½æ•°
def clean_g04(data):
    cleaned_data = []
    
    for item in data:
        cleaned_item = item.copy()
        
        # å¤„ç†actorå­—æ®µï¼Œç»Ÿä¸€ä¸ºActors
        if "actor" in cleaned_item:
            cleaned_item["Actors"] = cleaned_item.pop("actor")
        
        # å¤„ç†Basic flowå­—æ®µï¼Œç¡®ä¿æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
        if "Basic flow" in cleaned_item:
            basic_flow = cleaned_item["Basic flow"]
            if isinstance(basic_flow, list):
                # æ¸…ç†æ¯ä¸ªæ­¥éª¤ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_steps = []
                for step in basic_flow:
                    # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                    step = re.sub(r'^\d+\.?\s*', '', step)
                    # æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(step)
                    cleaned_steps.extend(sentences)
                cleaned_item["Basic flow"] = cleaned_steps
        
        cleaned_data.append(cleaned_item)
    
    return cleaned_data

# pnnl.json æ¸…æ´—å‡½æ•°
def clean_pnnl(data):
    cleaned_data = []
    
    for item in data:
        cleaned_item = item.copy()
        
        # å¤„ç†Brief Descriptionå­—æ®µï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
        if "Brief Description" in cleaned_item and isinstance(cleaned_item["Brief Description"], str):
            brief_desc = cleaned_item["Brief Description"]
            cleaned_item["Brief Description"] = brief_desc.strip()
        
        # å¤„ç†Basic Flowå­—æ®µï¼Œç¡®ä¿æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
        if "Basic Flow" in cleaned_item:
            basic_flow = cleaned_item["Basic Flow"]
            if isinstance(basic_flow, list):
                # æ¸…ç†æ¯ä¸ªæ­¥éª¤ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_steps = []
                for step in basic_flow:
                    # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                    step = re.sub(r'^\d+\.?\s*', '', step)
                    # æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(step)
                    cleaned_steps.extend(sentences)
                cleaned_item["Basic Flow"] = cleaned_steps
        
        # å¤„ç†Alt. Flowå­—æ®µï¼Œç¡®ä¿æ ¼å¼ä¸€è‡´
        if "Alt. Flow" in cleaned_item:
            alt_flow = cleaned_item["Alt. Flow"]
            if isinstance(alt_flow, list):
                # æ¸…ç†æ¯ä¸ªå¤‡é€‰æµç¨‹ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_alt_flow = []
                for flow in alt_flow:
                    if isinstance(flow, str):
                        # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                        flow = re.sub(r'^\d+\.?\s*', '', flow)
                        # æ‹†åˆ†æˆå¥å­
                        sentences = split_sentences(flow)
                        cleaned_alt_flow.extend(sentences)
                    else:
                        print(f"è­¦å‘Šï¼šåœ¨ Alt. Flow ä¸­å‘ç°éå­—ç¬¦ä¸²å…ƒç´ ï¼š{flow}")
                cleaned_item["Alt. Flow"] = cleaned_alt_flow
        
        cleaned_data.append(cleaned_item)
    
    return cleaned_data

# 0000 - gamma j.json æ¸…æ´—å‡½æ•°
def clean_gamma_j(data):
    cleaned_data = []
    
    for item in data:
        cleaned_item = item.copy()
        
        # å¤„ç†Basic flowå­—æ®µï¼Œç¡®ä¿æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
        if "Basic flow" in cleaned_item:
            basic_flow = cleaned_item["Basic flow"]
            if isinstance(basic_flow, list):
                # æ¸…ç†æ¯ä¸ªæ­¥éª¤ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_steps = []
                for step in basic_flow:
                    # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                    step = re.sub(r'^\d+\.?\s*', '', step)
                    # æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(step)
                    cleaned_steps.extend(sentences)
                cleaned_item["Basic flow"] = cleaned_steps
        
        # å¤„ç†Alt. Flowå­—æ®µï¼Œç¡®ä¿æ ¼å¼ä¸€è‡´
        if "Alt. Flow" in cleaned_item:
            alt_flow = cleaned_item["Alt. Flow"]
            if isinstance(alt_flow, list) and all(isinstance(x, list) for x in alt_flow):
                # å¤„ç†åµŒå¥—åˆ—è¡¨æƒ…å†µ
                flattened_alt_flow = []
                for flow_group in alt_flow:
                    for flow in flow_group:
                        # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                        flow = re.sub(r'^\d+\.?\s*', '', flow)
                        # æ‹†åˆ†æˆå¥å­
                        sentences = split_sentences(flow)
                        flattened_alt_flow.extend(sentences)
                cleaned_item["Alt. Flow"] = flattened_alt_flow
            elif isinstance(alt_flow, list):
                # æ¸…ç†æ¯ä¸ªå¤‡é€‰æµç¨‹ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_alt_flow = []
                for flow in alt_flow:
                    # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                    flow = re.sub(r'^\d+\.?\s*', '', flow)
                    # æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(flow)
                    cleaned_alt_flow.extend(sentences)
                cleaned_item["Alt. Flow"] = cleaned_alt_flow
        
        cleaned_data.append(cleaned_item)
    
    return cleaned_data

# 0000 - inventory.json æ¸…æ´—å‡½æ•°
def clean_inventory(data):
    cleaned_data = []
    
    for item in data:
        cleaned_item = item.copy()
        
        # å¤„ç†Basic Flowå­—æ®µï¼Œç¡®ä¿æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
        if "Basic Flow" in cleaned_item:
            basic_flow = cleaned_item["Basic Flow"]
            if isinstance(basic_flow, list):
                # æ¸…ç†æ¯ä¸ªæ­¥éª¤ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_steps = []
                for step in basic_flow:
                    # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                    step = re.sub(r'^\d+\.?\s*', '', step)
                    # æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(step)
                    cleaned_steps.extend(sentences)
                cleaned_item["Basic Flow"] = cleaned_steps
        
        # å¤„ç†Alt. Flowå­—æ®µï¼Œç¡®ä¿æ ¼å¼ä¸€è‡´
        if "Alt. Flow" in cleaned_item:
            alt_flow = cleaned_item["Alt. Flow"]
            if isinstance(alt_flow, list) and all(isinstance(x, list) for x in alt_flow):
                # å¤„ç†åµŒå¥—åˆ—è¡¨æƒ…å†µ
                flattened_alt_flow = []
                for flow_group in alt_flow:
                    for flow in flow_group:
                        # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                        flow = re.sub(r'^\d+\.?\s*', '', flow)
                        # æ‹†åˆ†æˆå¥å­
                        sentences = split_sentences(flow)
                        flattened_alt_flow.extend(sentences)
                cleaned_item["Alt. Flow"] = flattened_alt_flow
            elif isinstance(alt_flow, list):
                # æ¸…ç†æ¯ä¸ªå¤‡é€‰æµç¨‹ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_alt_flow = []
                for flow in alt_flow:
                    # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                    flow = re.sub(r'^\d+\.?\s*', '', flow)
                    # æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(flow)
                    cleaned_alt_flow.extend(sentences)
                cleaned_item["Alt. Flow"] = cleaned_alt_flow
        
        # å¤„ç†Exc. Flowå­—æ®µï¼Œç¡®ä¿æ ¼å¼ä¸€è‡´
        if "Exc. Flow" in cleaned_item:
            exc_flow = cleaned_item["Exc. Flow"]
            if isinstance(exc_flow, list) and all(isinstance(x, list) for x in exc_flow):
                # å¤„ç†åµŒå¥—åˆ—è¡¨æƒ…å†µ
                flattened_exc_flow = []
                for flow_group in exc_flow:
                    for flow in flow_group:
                        # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                        flow = re.sub(r'^\d+\.?\s*', '', flow)
                        # æ‹†åˆ†æˆå¥å­
                        sentences = split_sentences(flow)
                        flattened_exc_flow.extend(sentences)
                cleaned_item["Exc. Flow"] = flattened_exc_flow
        
        cleaned_data.append(cleaned_item)
    
    return cleaned_data

# 2009 - inventory 2.0.json æ¸…æ´—å‡½æ•°
def clean_inventory_2(data):
    cleaned_data = []
    
    for item in data:
        cleaned_item = item.copy()
        
        # å¤„ç†Actorå­—æ®µï¼Œç»Ÿä¸€ä¸ºActors
        if "Actor" in cleaned_item:
            cleaned_item["Actors"] = cleaned_item.pop("Actor")
        
        # å¤„ç†Basic Flowå­—æ®µï¼Œç¡®ä¿æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
        if "Basic Flow" in cleaned_item:
            basic_flow = cleaned_item["Basic Flow"]
            if isinstance(basic_flow, list):
                # æ¸…ç†æ¯ä¸ªæ­¥éª¤ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_steps = []
                for step in basic_flow:
                    # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                    step = re.sub(r'^\d+\.?\s*', '', step)
                    # æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(step)
                    cleaned_steps.extend(sentences)
                cleaned_item["Basic Flow"] = cleaned_steps
        
        # å¤„ç†Alt. Flowå­—æ®µï¼Œç¡®ä¿æ ¼å¼ä¸€è‡´
        if "Alt. Flow" in cleaned_item:
            alt_flow = cleaned_item["Alt. Flow"]
            if isinstance(alt_flow, list):
                # æ¸…ç†æ¯ä¸ªå¤‡é€‰æµç¨‹ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_alt_flow = []
                for flow in alt_flow:
                    # ç¡®ä¿ flow æ˜¯å­—ç¬¦ä¸²ç±»å‹
                    if isinstance(flow, str):
                        # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                        flow = re.sub(r'^\d+\.?\s*', '', flow)
                        # æ‹†åˆ†æˆå¥å­
                        sentences = split_sentences(flow)
                        cleaned_alt_flow.extend(sentences)
                    else:
                        print(f"è­¦å‘Šï¼šåœ¨ Alt. Flow ä¸­å‘ç°éå­—ç¬¦ä¸²å…ƒç´ ï¼š{flow}")
                cleaned_item["Alt. Flow"] = cleaned_alt_flow
        
        cleaned_data.append(cleaned_item)
    
    return cleaned_data

# viper.json æ¸…æ´—å‡½æ•°
def clean_viper(data):
    cleaned_data = []
    
    for item in data:
        cleaned_item = item.copy()
        
        # å¤„ç†Basic flowå­—æ®µï¼Œç¡®ä¿æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
        if "Basic flow" in cleaned_item:
            basic_flow = cleaned_item["Basic flow"]
            if isinstance(basic_flow, list):
                # æ¸…ç†æ¯ä¸ªæ­¥éª¤ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_steps = []
                for step in basic_flow:
                    if isinstance(step, dict) and "description" in step:
                        # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                        description = re.sub(r'^\d+\.?\s*', '', step["description"])
                        # æ‹†åˆ†æˆå¥å­
                        sentences = split_sentences(description)
                        cleaned_steps.extend(sentences)
                cleaned_item["Basic flow"] = cleaned_steps
        
        # å¤„ç†Alt. Flowå­—æ®µï¼Œç¡®ä¿æ ¼å¼ä¸€è‡´
        if "Alt. Flow" in cleaned_item:
            alt_flow = cleaned_item["Alt. Flow"]
            if isinstance(alt_flow, list):
                # æ¸…ç†æ¯ä¸ªå¤‡é€‰æµç¨‹ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_alt_flow = []
                for flow in alt_flow:
                    if isinstance(flow, dict) and "branching_action" in flow:
                        # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                        branching_action = re.sub(r'^\d+\.?\s*', '', flow["branching_action"])
                        # æ‹†åˆ†æˆå¥å­
                        sentences = split_sentences(branching_action)
                        cleaned_alt_flow.extend(sentences)
                cleaned_item["Alt. Flow"] = cleaned_alt_flow
        
        # å¤„ç†Preconditionå­—æ®µï¼Œç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼ä¸”æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
        if "Precondition" in cleaned_item:
            precond = cleaned_item["Precondition"]
            if isinstance(precond, list):
                cleaned_precond = []
                for cond in precond:
                    # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                    cond = re.sub(r'^\d+\.?\s*', '', cond)
                    # æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(cond)
                    cleaned_precond.extend(sentences)
                cleaned_item["Precondition"] = cleaned_precond
            elif isinstance(precond, str):
                cleaned_item["Precondition"] = split_sentences(precond)
        
        # å¤„ç†Postconditionå­—æ®µï¼Œç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼ä¸”æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
        if "Postcondition" in cleaned_item:
            postcond = cleaned_item["Postcondition"]
            if isinstance(postcond, list):
                cleaned_postcond = []
                for cond in postcond:
                    # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                    cond = re.sub(r'^\d+\.?\s*', '', cond)
                    # æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(cond)
                    cleaned_postcond.extend(sentences)
                cleaned_item["Postcondition"] = cleaned_postcond
            elif isinstance(postcond, str):
                cleaned_item["Postcondition"] = split_sentences(postcond)
        
        cleaned_data.append(cleaned_item)
    
    return cleaned_data

# hats.json æ¸…æ´—å‡½æ•°
def clean_hats(data):
    cleaned_data = []
    
    for item in data:
        cleaned_item = item.copy()
        
        # ç»Ÿä¸€å­—æ®µåç§°
        if "Use Case Name" in cleaned_item:
            cleaned_item["Name"] = cleaned_item.pop("Use Case Name")
        
        if "Description" in cleaned_item:
            cleaned_item["Brief Description"] = cleaned_item.pop("Description")
        
        # å¤„ç†Actorså­—æ®µï¼Œç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼
        if "Actors" in cleaned_item and not isinstance(cleaned_item["Actors"], list):
            actors = cleaned_item["Actors"]
            if isinstance(actors, str):
                actors_list = [actor.strip() for actor in re.split(r'[,;]', actors) if actor.strip()]
                cleaned_item["Actors"] = actors_list
        
        # å¤„ç†Preconditionå­—æ®µï¼Œç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼ä¸”æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
        if "Precondition" in cleaned_item:
            precond = cleaned_item["Precondition"]
            if isinstance(precond, list):
                cleaned_precond = []
                for cond in precond:
                    # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                    cond = re.sub(r'^\d+\.?\s*', '', cond)
                    # æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(cond)
                    cleaned_precond.extend(sentences)
                cleaned_item["Precondition"] = cleaned_precond
            elif isinstance(precond, str):
                cleaned_item["Precondition"] = split_sentences(precond)
        
        # å¤„ç†Basic flowå­—æ®µï¼Œç¡®ä¿æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
        if "Basic flow" in cleaned_item:
            basic_flow = cleaned_item["Basic flow"]
            if isinstance(basic_flow, list):
                # æ¸…ç†æ¯ä¸ªæ­¥éª¤ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_steps = []
                for step in basic_flow:
                    # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                    step = re.sub(r'^\d+\.?\s*', '', step)
                    # æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(step)
                    cleaned_steps.extend(sentences)
                cleaned_item["Basic flow"] = cleaned_steps
        
        # å¤„ç†Alternativeå­—æ®µï¼Œè½¬æ¢ä¸ºAlt. Flow
        if "Alternative" in cleaned_item:
            alt_flow = cleaned_item.pop("Alternative")
            if isinstance(alt_flow, list):
                # æ¸…ç†æ¯ä¸ªå¤‡é€‰æµç¨‹ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_alt_flow = []
                for flow in alt_flow:
                    if isinstance(flow, dict) and "steps" in flow:
                        for step in flow["steps"]:
                            # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                            step = re.sub(r'^\d+\.?\s*', '', step)
                            # æ‹†åˆ†æˆå¥å­
                            sentences = split_sentences(step)
                            cleaned_alt_flow.extend(sentences)
                cleaned_item["Alt. Flow"] = cleaned_alt_flow
        
        cleaned_data.append(cleaned_item)
    
    return cleaned_data

# keepass.json æ¸…æ´—å‡½æ•°
def clean_keepass(data):
    cleaned_data = []
    
    for item in data:
        cleaned_item = item.copy()
        
        # å¤„ç†Brief Descriptionå­—æ®µï¼Œç¡®ä¿æ˜¯å­—ç¬¦ä¸²æ ¼å¼
        if "Brief Description" in cleaned_item and not isinstance(cleaned_item["Brief Description"], str):
            brief_desc = cleaned_item["Brief Description"]
            if isinstance(brief_desc, list):
                cleaned_item["Brief Description"] = " ".join(brief_desc)
        
        # å¤„ç†Basic flowå­—æ®µï¼Œç¡®ä¿æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
        if "Basic flow" in cleaned_item:
            basic_flow = cleaned_item["Basic flow"]
            if isinstance(basic_flow, list):
                # æ¸…ç†æ¯ä¸ªæ­¥éª¤ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_steps = []
                for step in basic_flow:
                    # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                    step = re.sub(r'^\d+\.?\s*', '', step)
                    # æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(step)
                    cleaned_steps.extend(sentences)
                cleaned_item["Basic flow"] = cleaned_steps
        
        # å¤„ç†Alt. Flowå­—æ®µï¼Œç¡®ä¿æ ¼å¼ä¸€è‡´
        if "Alt. Flow" in cleaned_item:
            alt_flow = cleaned_item["Alt. Flow"]
            if isinstance(alt_flow, list) and all(isinstance(x, list) for x in alt_flow):
                # å¤„ç†åµŒå¥—åˆ—è¡¨æƒ…å†µ
                flattened_alt_flow = []
                for flow_group in alt_flow:
                    for flow in flow_group:
                        # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                        flow = re.sub(r'^\d+\.?\s*', '', flow)
                        # æ‹†åˆ†æˆå¥å­
                        sentences = split_sentences(flow)
                        flattened_alt_flow.extend(sentences)
                cleaned_item["Alt. Flow"] = flattened_alt_flow
        
        # å¤„ç†Postconditionå­—æ®µï¼Œç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼ä¸”æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
        if "Postcondition" in cleaned_item:
            postcond = cleaned_item["Postcondition"]
            if isinstance(postcond, list):
                cleaned_postcond = []
                for cond in postcond:
                    # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                    cond = re.sub(r'^\d+\.?\s*', '', cond)
                    # æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(cond)
                    cleaned_postcond.extend(sentences)
                cleaned_item["Postcondition"] = cleaned_postcond
            elif isinstance(postcond, str):
                cleaned_item["Postcondition"] = split_sentences(postcond)
        
        cleaned_data.append(cleaned_item)
    
    return cleaned_data

# model manager.json æ¸…æ´—å‡½æ•°
def clean_model_manager(data):
    cleaned_data = []
    
    for item in data:
        cleaned_item = item.copy()
        
        # å¤„ç†Actorå­—æ®µï¼Œç»Ÿä¸€ä¸ºActors
        if "Actor" in cleaned_item:
            actors = cleaned_item.pop("Actor")
            if isinstance(actors, list):
                cleaned_item["Actors"] = actors
            elif isinstance(actors, str):
                actors_list = [actor.strip() for actor in re.split(r'[,;]', actors) if actor.strip()]
                cleaned_item["Actors"] = actors_list
        
        # å¤„ç†Brief Descriptionå­—æ®µï¼Œç¡®ä¿æ˜¯å­—ç¬¦ä¸²æ ¼å¼
        if "Brief Description" in cleaned_item:
            brief_desc = cleaned_item["Brief Description"]
            if isinstance(brief_desc, list):
                cleaned_item["Brief Description"] = " ".join(brief_desc)
            elif isinstance(brief_desc, str):
                # ç¡®ä¿æè¿°ä»¥æ ‡ç‚¹ç¬¦å·ç»“å°¾
                if not re.search(r'[.!?]$', brief_desc):
                    cleaned_item["Brief Description"] = brief_desc + "."
        
        # å¤„ç†Basic flowå­—æ®µï¼Œç¡®ä¿æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
        if "Basic flow" in cleaned_item:
            basic_flow = cleaned_item["Basic flow"]
            if isinstance(basic_flow, list):
                # æ¸…ç†æ¯ä¸ªæ­¥éª¤ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å¥å­
                cleaned_steps = []
                for step in basic_flow:
                    # ç§»é™¤æ•°å­—å‰ç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
                    step = re.sub(r'^\d+\.?\s*', '', step)
                    # æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(step)
                    cleaned_steps.extend(sentences)
                cleaned_item["Basic flow"] = cleaned_steps
        
        cleaned_data.append(cleaned_item)
    
    return cleaned_data

# ä¸»å‡½æ•°ï¼šå¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰JSONæ–‡ä»¶
def clean_all_json_files(directory_path, output_directory=None):
    """
    æ¸…æ´—å’Œæ ‡å‡†åŒ–ç›®å½•ä¸‹çš„æ‰€æœ‰JSONæ–‡ä»¶
    
    Args:
        directory_path: JSONæ–‡ä»¶æ‰€åœ¨ç›®å½•è·¯å¾„
        output_directory: è¾“å‡ºç›®å½•è·¯å¾„ï¼Œå¦‚æœä¸ºNoneï¼Œåˆ™è¦†ç›–åŸæ–‡ä»¶
    """
    if output_directory and not os.path.exists(output_directory):
        os.makedirs(output_directory)
    
    # è·å–ç›®å½•ä¸‹æ‰€æœ‰çš„JSONæ–‡ä»¶
    json_files = [f for f in os.listdir(directory_path) if f.endswith('.json') and not f.startswith('README')]
    
    for file_name in json_files:
        file_path = os.path.join(directory_path, file_name)
        
        print(f"æ­£åœ¨å¤„ç†æ–‡ä»¶ {file_name}...")
        
        # è¯»å–JSONæ–‡ä»¶
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æ ¹æ®æ–‡ä»¶åé€‰æ‹©ç›¸åº”çš„æ¸…æ´—å‡½æ•°
        if file_name == "iTrust.json":
            cleaned_data = clean_itrust(data)
        elif file_name == "viper.json":
            cleaned_data = clean_viper(data)
        elif file_name == "hats.json":
            cleaned_data = clean_hats(data)
        elif file_name == "keepass.json":
            cleaned_data = clean_keepass(data)
        elif file_name == "model manager.json":
            cleaned_data = clean_model_manager(data)
        # if file_name == "eANCI_en.json":
        #     cleaned_data = clean_eanci(data)
        # elif file_name == "SMOS_en.json":
        #     cleaned_data = clean_smos(data)
        # elif file_name == "eTour.json":
        #     cleaned_data = clean_etour(data)
        # elif file_name == "easyClinic.json":
        #     cleaned_data = clean_easyclinic(data)
        # elif file_name == "g02-uc-cm-req.json":
        #     cleaned_data = clean_g02(data)
        # elif file_name == "g04-uc-req.json":
        #     cleaned_data = clean_g04(data)
        # elif file_name == "pnnl.json":
        #     cleaned_data = clean_pnnl(data)
        # elif file_name == "0000 - gamma j.json":
        #     cleaned_data = clean_gamma_j(data)
        # elif file_name == "0000 - inventory.json":
        #     cleaned_data = clean_inventory(data)
        # elif file_name == "2009 - inventory 2.0.json":
        #     cleaned_data = clean_inventory_2(data)
        else:
            print(f"æœªæ‰¾åˆ° {file_name} çš„æ¸…æ´—å‡½æ•°ï¼Œè·³è¿‡å¤„ç†")
            continue
        
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        if output_directory:
            output_path = os.path.join(output_directory, f"cleaned_{file_name}")
        else:
            output_path = file_path
        
        # ä¿å­˜æ¸…æ´—åçš„æ•°æ®
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(cleaned_data, f, ensure_ascii=False, indent=4)
        
        print(f"å·²å®Œæˆ {file_name} çš„æ¸…æ´—å’Œæ ‡å‡†åŒ–ï¼Œä¿å­˜åˆ° {output_path}")

# è¯»å–ç”¨dictä¿å­˜çš„uc
def read_uc_from_json(file_path):
    use_case_list = []
    with open(file_path, 'r', encoding='utf-8') as file:
        for line in file:
            # line = line.replace("'", '"')  # æœ‰æ—¶å€™æ•°æ®é›†ä¸­ä¼šæœ‰å¤šä½™çš„å•å¼•å·æˆ–è€…åŒå¼•å·
            try:
                uc = json.loads(line)
                use_case_list.append(uc)
            except json.JSONDecodeError as e:
                print(f"é”™è¯¯ä¿¡æ¯: {e},  Line: {inspect.currentframe().f_lineno}, jsonè¯»å–å¤±è´¥")
    return use_case_list

# iTrust.json æ¸…æ´—å‡½æ•°
def clean_itrust(data):
    cleaned_data = []
    
    # æŒ‰é¡ºåºé‡æ–°ç¼–å·
    new_id = 1
    
    for item in data:
        cleaned_item = item.copy()
        
        # é‡æ–°ç¼–å†™id
        cleaned_item["id"] = str(new_id)
        new_id += 1
        
        # ç§»é™¤ Original å­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if "Original" in cleaned_item:
            cleaned_item.pop("Original")
        
        # å¤„ç†Preconditionå­—æ®µï¼Œç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼
        if "Precondition" in cleaned_item and isinstance(cleaned_item["Precondition"], str):
            precond = cleaned_item["Precondition"]
            cleaned_item["Precondition"] = split_sentences(precond)
        
        # å¤„ç†Basic flowå­—æ®µï¼Œç¡®ä¿æ¯ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¥å­
        if "Basic flow" in cleaned_item and isinstance(cleaned_item["Basic flow"], str):
            basic_flow = cleaned_item["Basic flow"]
            cleaned_item["Basic flow"] = split_sentences(basic_flow)
        
        # å¤„ç†Sub. Flowå­—æ®µï¼Œæ¸…ç†æ¯ä¸ªå­æµç¨‹çš„æ–‡æœ¬
        if "Sub. Flow" in cleaned_item and isinstance(cleaned_item["Sub. Flow"], list):
            sub_flows = cleaned_item["Sub. Flow"]
            cleaned_sub_flows = []
            
            for flow in sub_flows:
                if isinstance(flow, dict) and "id" in flow and "text" in flow:
                    cleaned_text = flow["text"]
                    
                    # ç§»é™¤æ–‡æœ¬æœ«å°¾å¯èƒ½åŒ…å«çš„Alternative Flowsæ ‡è®°
                    if "Alternative Flows:" in cleaned_text:
                        cleaned_text = cleaned_text.split("Alternative Flows:")[0].strip()
                    
                    # æ¸…ç†æ–‡æœ¬å¹¶æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(cleaned_text)
                    
                    cleaned_sub_flows.append({
                        "id": flow["id"],
                        "text": sentences if len(sentences) > 1 else cleaned_text
                    })
            
            cleaned_item["Sub. Flow"] = cleaned_sub_flows
        
        # å¤„ç†Alt. Flowå­—æ®µï¼Œæ¸…ç†æ¯ä¸ªå¤‡é€‰æµç¨‹çš„æ–‡æœ¬
        if "Alt. Flow" in cleaned_item and isinstance(cleaned_item["Alt. Flow"], list):
            alt_flows = cleaned_item["Alt. Flow"]
            cleaned_alt_flows = []
            
            for flow in alt_flows:
                if isinstance(flow, dict) and "id" in flow and "text" in flow:
                    cleaned_text = flow["text"]
                    
                    # æ¸…ç†æ–‡æœ¬å¹¶æ‹†åˆ†æˆå¥å­
                    sentences = split_sentences(cleaned_text)
                    
                    cleaned_alt_flows.append({
                        "id": flow["id"],
                        "text": sentences if len(sentences) > 1 else cleaned_text
                    })
            
            cleaned_item["Alt. Flow"] = cleaned_alt_flows
        
        # ç»Ÿä¸€å­—æ®µåç§°ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if "Basic flow" in cleaned_item:
            cleaned_item["Basic Flow"] = cleaned_item.pop("Basic flow")
        
        cleaned_data.append(cleaned_item)
    
    return cleaned_data

def get_unique_keys_from_files(directory):
    from imports import OrderedDict
    """å¤„ç†ç›®å½•ä¸­æ‰€æœ‰JSONæ–‡ä»¶ï¼Œè¾“å‡ºæ¯ä¸ªæ–‡ä»¶å­—å…¸çš„å”¯ä¸€é”®"""
    for filename in os.listdir(directory):
        if filename.endswith('.json'):
            filepath = os.path.join(directory, filename)
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # éªŒè¯æ•°æ®ç»“æ„ï¼šå¿…é¡»æ˜¯åˆ—è¡¨ï¼Œä¸”å…ƒç´ ä¸ºå­—å…¸
                if not isinstance(data, list):
                    print(f"âš ï¸ æ–‡ä»¶ {filename} é”™è¯¯: é¡¶çº§ç»“æ„ä¸æ˜¯åˆ—è¡¨ï¼ˆå®é™…ç±»å‹: {type(data).__name__}ï¼‰")
                    continue
                
                # æ”¶é›†æ‰€æœ‰å”¯ä¸€é”®ï¼ˆä¿æŒåŸå§‹é¡ºåºï¼‰
                unique_keys = OrderedDict()
                for item in data:
                    if not isinstance(item, dict):
                        print(f"âš ï¸ æ–‡ä»¶ {filename} ä¸­æœ‰éå­—å…¸å…ƒç´ ï¼ˆç±»å‹: {type(item).__name__}ï¼‰")
                        continue
                    
                    for key in item.keys():
                        # ä½¿ç”¨OrderedDictä¿ç•™å‘ç°é¡ºåº
                        unique_keys[key] = None
                
                # è½¬æ¢ä¸ºåˆ—è¡¨è¾“å‡º
                key_list = list(unique_keys.keys())
                if key_list:
                    print(f"ğŸ“‚ æ–‡ä»¶ '{filename}' åŒ…å«çš„å”¯ä¸€é”® ({len(key_list)}ä¸ª):")
                    print(", ".join(key_list))
                else:
                    print(f"ğŸ“‚ æ–‡ä»¶ '{filename}' æ²¡æœ‰å‘ç°ä»»ä½•é”®")
                print("â”€" * 60)
            
            except Exception as e:
                print(f"â›” å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {str(e)}")
                print("â”€" * 60)

if __name__ == "__main__":
    task_name = 'find_exc_flow_in_viper'

    print(f"*** task_name: {task_name} ***")

    # ä»txtæ–‡ä»¶æå–ç”¨ä¾‹ï¼Œå­˜æ”¾åœ¨jsonæ–‡ä»¶ä¸­
    if task_name == 'clean_json':
        # è®¾ç½®è¾“å…¥å’Œè¾“å‡ºç›®å½•
        input_directory = "e:/Trae_project/ConditionOfUCS/0_Data/2_json_dataset"
        output_directory = "e:/Trae_project/ConditionOfUCS/0_Data/3_cleaned_json_dataset"
        
        # å¤„ç†æŒ‡å®šçš„JSONæ–‡ä»¶
        json_files = ["viper.json", "hats.json", "keepass.json", "model manager.json"]
        
        for file_name in json_files:
            file_path = os.path.join(input_directory, file_name)
            
            if not os.path.exists(file_path):
                print(f"æ–‡ä»¶ {file_name} ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†")
                continue
                
            print(f"æ­£åœ¨å¤„ç†æ–‡ä»¶ {file_name}...")
            
            # è¯»å–JSONæ–‡ä»¶
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æ ¹æ®æ–‡ä»¶åé€‰æ‹©ç›¸åº”çš„æ¸…æ´—å‡½æ•°
            if file_name == "viper.json":
                cleaned_data = clean_viper(data)
            elif file_name == "hats.json":
                cleaned_data = clean_hats(data)
            elif file_name == "keepass.json":
                cleaned_data = clean_keepass(data)
            elif file_name == "model manager.json":
                cleaned_data = clean_model_manager(data)
            else:
                print(f"æœªæ‰¾åˆ° {file_name} çš„æ¸…æ´—å‡½æ•°ï¼Œè·³è¿‡å¤„ç†")
                continue
            
            # ç¡®å®šè¾“å‡ºè·¯å¾„
            if not os.path.exists(output_directory):
                os.makedirs(output_directory)
                
            output_path = os.path.join(output_directory, f"cleaned_{file_name}")
            
            # ä¿å­˜æ¸…æ´—åçš„æ•°æ®
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(cleaned_data, f, ensure_ascii=False, indent=4)
            
            print(f"å·²å®Œæˆ {file_name} çš„æ¸…æ´—å’Œæ ‡å‡†åŒ–ï¼Œä¿å­˜åˆ° {output_path}")

    # è¾“å‡ºæ¯ä¸ªæ•°æ®é›†çš„ucçš„keyçš„ç§ç±»ï¼Œç”¨äºç»Ÿä¸€
    if task_name == "output_key":
        json_dir = "e:/Trae_project/ConditionOfUCS/0_Data/3_cleaned_json_dataset"
        get_unique_keys_from_files(json_dir)

    # è¯†åˆ«å‡ºviperæ•°æ®é›†ä¸­çš„å¼‚å¸¸æµ
    if task_name == "find_exc_flow_in_viper":
        viper_path = "E:/Trae_project/ConditionOfUCS/0_Data/3_cleaned_json_dataset/cleaned_viper.json"
        # åŠ è½½viper.jsonæ–‡ä»¶
        with open(viper_path, 'r', encoding='utf-8') as f:
            viper_data = json.load(f)

        for uc in viper_data:
            uc['Exc. Flow'] = []
            if len(uc['Alt. Flow']) > 1 : # æŒ‰ç…§åˆ—è¡¨å­˜å‚¨çš„
                for i in range(len(uc['Alt. Flow'])-1, -1, -1):
                    if '"Error!"' in uc['Alt. Flow'][i][0]:
                        uc['Exc. Flow'].append([uc['Alt. Flow'][i][0]])
                        del uc['Alt. Flow'][i]
            elif len(uc['Alt. Flow']) == 1: # æŒ‰ç…§å­—ç¬¦ä¸²å­˜å‚¨çš„
                if '"Error!"' in uc['Alt. Flow'][0]:
                    uc['Exc. Flow'].append([uc['Alt. Flow'][0]])
                    uc['Alt. Flow'] = []
            else:
                    print(str(uc['id']) + uc['Name'] + "alt flow æœ‰é—®é¢˜")    
        
        # ä¿å­˜
        with open(viper_path, 'w', encoding='utf-8') as f:
            json.dump(viper_data, f, ensure_ascii=False, indent=4)


        



